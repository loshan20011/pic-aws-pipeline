version: 0.2

phases:
  install:
    commands:
      - set -e  # Exit script on error
      - yum update -y
      - yum install -y git python3 python3-pip jq dnf
      - pip install awscli
      - curl -o aws-iam-authenticator https://s3.us-west-2.amazonaws.com/amazon-eks/1.21.2/2021-07-05/bin/linux/amd64/aws-iam-authenticator
      - chmod +x aws-iam-authenticator && mv aws-iam-authenticator /usr/local/bin/
      - curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.21.0/bin/linux/amd64/kubectl
      - chmod +x kubectl && mv kubectl /usr/local/bin/
      - curl -sSL https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
      - helm version
      - kubectl version --client

  pre_build:
    commands:
      - echo "Updating kubeconfig..."
      - aws eks --region $CLUSTER_REGION update-kubeconfig --name $EKS_CLUSTER_NAME --role-arn $EKS_CODEBUILD_ROLE_ARN
      - export KUBECONFIG=/root/.kube/config
      - chmod 0600 ~/.kube/config
      - echo "Checking AWS credentials..."
      - aws sts get-caller-identity
      - echo "Checking Kubernetes contexts..."
      - kubectl config get-contexts
      - echo "Verifying EKS authentication..."
      - export KUBERNETES_EXEC_INFO=$(aws eks get-token --cluster-name $EKS_CLUSTER_NAME)
      - echo "Authentication successful!"
      - echo "Checking Kubernetes access..."
      - kubectl auth can-i '*' '*'

  build:
    commands:
      - echo "Deploying Helm Chart..."
      - helm upgrade --install $RELEASE_NAME ./kubernetes-is -n wso2is
        --set deployment.ingress.hostName=$CLOUD_FRONT_HOST
        --set deployment.ingress.aws.enabled=true
        --set deployment.externalJKS.enabled=true
        --set deployment.persistence.aws.enabled=true
        --set pv-pvc.deployment.persistence.aws.volumeHandle=$VOLUME_HANDLE 
        --set deployment.secretStore.aws.enabled=true 
        --set deployment.secretStore.aws.secretManager.region=$CLUSTER_REGION 
        --set deployment.image.registry=$ECR_REGISTRY 
        --set deployment.image.repository=$ECR_IMAGE 
        --set deployment.image.tag=$ECR_TAG 
        --set deploymentToml.database.identity.type=postgre 
        --set deploymentToml.database.shared.type=postgre 
        --set deploymentToml.database.user.type=postgre 
        --set deploymentToml.database.consent.type=postgre 
        --set deploymentToml.database.identity.url=jdbc:postgresql://$RDS_HOST:5432/identitydb 
        --set deploymentToml.database.shared.url=jdbc:postgresql://$RDS_HOST:5432/shareddb 
        --set deploymentToml.database.user.url=jdbc:postgresql://$RDS_HOST:5432/userdb 
        --set deploymentToml.database.consent.url=jdbc:postgresql://$RDS_HOST:5432/consentdb 
        --set deploymentToml.database.identity.driver=org.postgresql.Driver 
        --set deploymentToml.database.shared.driver=org.postgresql.Driver 
        --set deploymentToml.database.user.driver=org.postgresql.Driver 
        --set deploymentToml.database.consent.driver=org.postgresql.Driver 
        --set deploymentToml.keystore.tls.fileName=tls.jks 
        --set deploymentToml.keystore.primary.fileName=primary.jks 
        --set deploymentToml.keystore.internal.fileName=internal.jks 
        --set deployment.apparmor.enabled="false" 
        --set deployment.rbac.annotations."eks\.amazonaws\.com/role-arn"=$IRSA_ROLE_ARN
        --set fullnameOverride=$RELEASE_NAME
        --set pv-pvc.fullnameOverride=$RELEASE_NAME

  post_build:
    commands:
      - echo "Verifying deployed resources..."
      - kubectl get pods -A
      - kubectl get services -A
      - kubectl get pvc -n wso2is

artifacts:
  files:
    - '**/*'  # This includes all files and directories in the build's workspace
